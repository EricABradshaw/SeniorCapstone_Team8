{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toh-TTsEw0uA"
      },
      "source": [
        "#SteGuz : Image Steganography using CNN\n",
        "### A Tensorflow Implementation\n",
        "#### Published June 2022\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR_kWxJmw0uO"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAkobh2sw0uO",
        "outputId": "41f213ea-0d4b-4759-9c48-dd3e0334df0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['random', 'datetime']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "%pylab inline\n",
        "%load_ext tensorboard\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image,ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "from datetime import datetime\n",
        "from os.path import join\n",
        "from tensorflow.keras import layers, optimizers\n",
        "\n",
        "#image metrics:\n",
        "import numpy as np\n",
        "from skimage import data, img_as_float\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import mean_squared_error\n",
        "\n",
        "#for use in mounting google drive image dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "#tf.compat.v1.enable_eager_execution()\n",
        "#tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ony7OQCw0uP"
      },
      "source": [
        "## Configuration\n",
        "All Configuration related information is represented in CAPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-xwuHQ3w0uP"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = \"/content/drive/MyDrive/\"\n",
        "GDRIVE_PATH = ROOT_PATH + \"Yashi/\"\n",
        "TRAIN_PATH = ROOT_PATH + \"Training-Data/\"\n",
        "LOGS_PATH = GDRIVE_PATH + \"logs/\"\n",
        "CHECKPOINTS_PATH = GDRIVE_PATH + \"Saved-Stego-Models/checkpoints_NoNL/\"\n",
        "SAVED_STEGO_MODEL_DIRECTORY_PATH = GDRIVE_PATH + \"Saved-Stego-Models/\"\n",
        "MODEL_PATH = SAVED_STEGO_MODEL_DIRECTORY_PATH\n",
        "METRIC_TESTING_IMAGES_PATH = GDRIVE_PATH + \"Results/Final Network/\"\n",
        "SHOULD_CONTINUE_TRAINING_NETWORK = True\n",
        "model_paths_list = ['/content/drive/MyDrive/Yashi/Saved-Stego-Models/']\n",
        "# Batch size refers to the number of examples from the training dataset that are used in the estimate of the error\n",
        "# gradient. Smaller batch sizes are preferred over larger ones because small batch sizes are noisy, which offer a regularizing\n",
        "# effect and lower generalization error. They also make it easier to fit one batch worth of training data in memory.\n",
        "#BATCH_SIZE = 50\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "EPOCHS = 1\n",
        "# The learning rate is a hyperparameter that controls how much the model changes in response to the estimated error\n",
        "# each time the model weights are updated. A small learning rate may result in a long training process, while a large\n",
        "# learning rate may result in learning a sub-optimal set of weights too quickly or an unstable training process.\n",
        "# The learning rate may be the most important hyperparameter when configuring the neural network.\n",
        "#\n",
        "# Source: https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
        "#LEARNING_RATE = .0001\n",
        "LEARNING_RATE = .0002\n",
        "optimizer = tf.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "# Momentum is used to increase the speed of the optimization process.\n",
        "#BETA = .75\n",
        "BETA = .75\n",
        "\n",
        "# Save the model as Trained_Model_Month_Day_Year_HH_MM_SS\n",
        "#currentDateTime = datetime.now().strftime(\"%B_%m_%Y_%H_%M_%S\")\n",
        "#Changed by @Khalifa\n",
        "currentDateTime = datetime.now().strftime(\"%m-%d-%Y\")\n",
        "EXP_NAME = f\"Final_Trained_Model_P75_TF2_{currentDateTime}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCugMzH3w0uQ"
      },
      "source": [
        "## Method definitions\n",
        "The images are first converted to float values between 0 and 1.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCFuazCZdspq"
      },
      "outputs": [],
      "source": [
        "def get_img_batch(files_list, batch_size=BATCH_SIZE, size=(224, 224)):\n",
        "    # Populates a batch of images with random training images.\n",
        "    #\n",
        "    # param   files_list                            List of files to obtain the random images from\n",
        "    # param   batch_size                            Batch size (defaults to specified BATCH_SIZE)\n",
        "    # param   size                                  Used to set the size of the cropped images (default 224 x 224 px).\n",
        "    #\n",
        "    # return  batch_cover,batch_secret              A tuple with the batch of cover and secret images ready for processing\n",
        "\n",
        "    batch_cover = []\n",
        "    batch_secret = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img_secret_path = random.choice(files_list)\n",
        "        img_cover_path = random.choice(files_list)\n",
        "\n",
        "        img_secret = Image.open(img_secret_path).convert(\"RGB\")\n",
        "        img_cover = Image.open(img_cover_path).convert(\"RGB\")\n",
        "\n",
        "        # ImageOps returns a sized and cropped version of the image, cropped to the requested aspect ratio (img_secret) and size.\n",
        "        # The np.array method converts the image to sized and cropped image into an array of float32 values\n",
        "        img_secret = np.array(ImageOps.fit(img_secret, size), dtype=np.float32)\n",
        "        img_cover = np.array(ImageOps.fit(img_cover, size), dtype=np.float32)\n",
        "\n",
        "        # TODO: Why is this here?\n",
        "        img_secret /= 255.\n",
        "        img_cover /= 255.\n",
        "\n",
        "        batch_cover.append(img_cover)\n",
        "        batch_secret.append(img_secret)\n",
        "\n",
        "    batch_cover, batch_secret = np.array(batch_cover), np.array(batch_secret)\n",
        "\n",
        "    return batch_cover, batch_secret\n",
        "\n",
        "def get_prep_network_op(secret_tensor):\n",
        "    # Defining convolutional layers for different branches\n",
        "    conv_branches = []\n",
        "    for kernel_size in [(3, 3), (4, 4), (5, 5)]:\n",
        "        conv = secret_tensor\n",
        "        for _ in range(5):\n",
        "            conv = layers.Conv2D(50, kernel_size, padding='same', activation='relu')(conv)\n",
        "        conv_branches.append(conv)\n",
        "\n",
        "    # Concatenating branches\n",
        "    concat = layers.Concatenate(axis=3)(conv_branches)\n",
        "\n",
        "    # Additional convolution layers after concatenation\n",
        "    conv_final = [layers.Conv2D(50, size, padding='same', activation='relu')(concat) for size in [(5, 5), (4, 4), (3, 3)]]\n",
        "\n",
        "    # Final concatenation\n",
        "    concat_final = layers.Concatenate(axis=3)(conv_final)\n",
        "\n",
        "    return concat_final\n",
        "\n",
        "\n",
        "def get_hiding_network_op(cover_tensor, prep_output):\n",
        "    #print(\"Shape of hiding cover tensor:\", cover_tensor.shape)\n",
        "    #print(\"Shape of hiding secret tensor:\", prep_output.shape)\n",
        "\n",
        "    # Concatenating cover and prepared secret tensors\n",
        "    concat_input = layers.Concatenate(axis=3)([cover_tensor, prep_output])\n",
        "    #print(\"Shape of hiding concat_input tensor:\", concat_input.shape)\n",
        "\n",
        "    # Defining convolutional layers for different branches\n",
        "    conv_branches = []\n",
        "    for kernel_size in [(3, 3), (4, 4), (5, 5)]:\n",
        "        conv = concat_input\n",
        "        for _ in range(5):\n",
        "            conv = layers.Conv2D(50, kernel_size, padding='same', activation='relu')(conv)\n",
        "        conv_branches.append(conv)\n",
        "        #print(f\"Shape of hiding {kernel_size[0]}x{kernel_size[1]} concat tensor:\", conv.shape)\n",
        "\n",
        "    # Concatenating branches\n",
        "    concat_1 = layers.Concatenate(axis=3)(conv_branches)\n",
        "    #print(\"Shape of hiding initial concat tensor:\", concat_1.shape)\n",
        "\n",
        "    # Additional convolution layers after concatenation\n",
        "    conv_final = [layers.Conv2D(50, size, padding='same', activation='relu')(concat_1) for size in [(5, 5), (4, 4), (3, 3)]]\n",
        "\n",
        "    # Final concatenation\n",
        "    concat_final = layers.Concatenate(axis=3)(conv_final)\n",
        "    output = layers.Conv2D(3, (1, 1), padding='same', activation='relu', name='hiding_output')(concat_final)\n",
        "    #print(\"Shape of hiding final concat tensor:\", output.shape)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def get_reveal_network_op(container_tensor):\n",
        "    # Defining convolutional layers for different branches\n",
        "    conv_branches = []\n",
        "    for kernel_size in [(3, 3), (4, 4), (5, 5)]:\n",
        "        conv = container_tensor\n",
        "        for _ in range(5):\n",
        "            conv = layers.Conv2D(50, kernel_size, padding='same', activation='relu')(conv)\n",
        "        conv_branches.append(conv)\n",
        "\n",
        "    # Concatenating branches\n",
        "    concat_1 = layers.Concatenate(axis=3)(conv_branches)\n",
        "\n",
        "    # Additional convolution layers after concatenation\n",
        "    conv_final = [layers.Conv2D(50, size, padding='same', activation='relu')(concat_1) for size in [(5, 5), (4, 4), (3, 3)]]\n",
        "\n",
        "    # Final concatenation\n",
        "    concat_final = layers.Concatenate(axis=3)(conv_final)\n",
        "    output = layers.Conv2D(3, (1, 1), padding='same', name='reveal_output')(concat_final)\n",
        "\n",
        "    #print(\"Shape of reveal initial concat tensor:\", concat_final.shape)\n",
        "    #print(\"Shape of reveal output tensor:\", output.shape)\n",
        "\n",
        "    return output\n",
        "\n",
        "def get_loss_op(secret_true, secret_pred, cover_true, cover_pred, BETA):\n",
        "    # Weight for PSNR in the combined loss calculation\n",
        "    psnr_weight = 1.0 / 40.0\n",
        "\n",
        "    # Calculate SSIM, PSNR, and MSE for secret and cover images\n",
        "    secret_ssim = tf.reduce_mean(tf.image.ssim(secret_true, secret_pred, max_val=255))\n",
        "    secret_psnr = tf.reduce_mean(tf.image.psnr(secret_true, secret_pred, max_val=255))\n",
        "    # Use TensorFlow operations to compute MSE\n",
        "    secret_mse = tf.reduce_mean(tf.square(secret_true - secret_pred))\n",
        "\n",
        "    cover_ssim = tf.reduce_mean(tf.image.ssim(cover_true, cover_pred, max_val=255))\n",
        "    cover_psnr = tf.reduce_mean(tf.image.psnr(cover_true, cover_pred, max_val=255))\n",
        "    # Use TensorFlow operations to compute MSE\n",
        "    cover_mse = tf.reduce_mean(tf.square(cover_true - cover_pred))\n",
        "\n",
        "    # Combine SSIM and PSNR for secret and cover images, and apply beta weighting\n",
        "    secret_loss = BETA * ((psnr_weight * secret_psnr) + secret_ssim) + (1 - BETA) * secret_mse\n",
        "    cover_loss = BETA * ((psnr_weight * cover_psnr) + cover_ssim) + (1 - BETA) * cover_mse\n",
        "\n",
        "    # Calculate final loss\n",
        "    final_loss = cover_loss + secret_loss\n",
        "\n",
        "    return -1 * final_loss, secret_mse, cover_mse\n",
        "\n",
        "\n",
        "\n",
        "def get_tensor_to_img_op(tensor):\n",
        "    # Clip the tensor values to be in the range [0, 1]\n",
        "    return tf.clip_by_value(tensor, 0, 1)\n",
        "\n",
        "\n",
        "def prepare_training_graph(secret_tensor, cover_tensor, global_step_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor, prep_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(hiding_output_op)\n",
        "\n",
        "    loss_op, secret_loss_op, cover_loss_op = get_loss_op(secret_tensor, reveal_output_op, cover_tensor, hiding_output_op, BETA)\n",
        "\n",
        "    # Define the optimizer and the training operation\n",
        "    optimizer = tf.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    maximize_op = optimizer.minimize((-1 * loss_op), global_step=global_step_tensor)\n",
        "\n",
        "    # Create summary operations for TensorBoard\n",
        "    with tf.name_scope('train'):\n",
        "        tf.summary.scalar('loss', -loss_op)\n",
        "        tf.summary.scalar('reveal_net_loss', secret_loss_op)\n",
        "        tf.summary.scalar('cover_net_loss', cover_loss_op)\n",
        "        tf.summary.image('secret', get_tensor_to_img_op(secret_tensor), max_outputs=1)\n",
        "        tf.summary.image('cover', get_tensor_to_img_op(cover_tensor), max_outputs=1)\n",
        "        tf.summary.image('hidden', get_tensor_to_img_op(hiding_output_op), max_outputs=1)\n",
        "        tf.summary.image('revealed', get_tensor_to_img_op(reveal_output_op), max_outputs=1)\n",
        "\n",
        "    merged_summary_op = tf.summary.merge_all()\n",
        "\n",
        "    return maximize_op, merged_summary_op\n",
        "\n",
        "\n",
        "def prepare_test_graph(secret_tensor, cover_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor, prep_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(hiding_output_op)\n",
        "\n",
        "    loss_op, secret_loss_op, cover_loss_op = get_loss_op(secret_tensor, reveal_output_op, cover_tensor, hiding_output_op)\n",
        "\n",
        "    # Create summary operations for TensorBoard\n",
        "    with tf.name_scope('test'):\n",
        "        tf.summary.scalar('loss', loss_op)\n",
        "        tf.summary.scalar('reveal_net_loss', secret_loss_op)\n",
        "        tf.summary.scalar('cover_net_loss', cover_loss_op)\n",
        "        tf.summary.image('secret', get_tensor_to_img_op(secret_tensor), max_outputs=1)\n",
        "        tf.summary.image('cover', get_tensor_to_img_op(cover_tensor), max_outputs=1)\n",
        "        tf.summary.image('hidden', get_tensor_to_img_op(hiding_output_op), max_outputs=1)\n",
        "        tf.summary.image('revealed', get_tensor_to_img_op(reveal_output_op), max_outputs=1)\n",
        "\n",
        "    merged_summary_op = tf.summary.merge_all()\n",
        "\n",
        "    return merged_summary_op\n",
        "\n",
        "\n",
        "def prepare_deployment_graph(secret_tensor, cover_tensor, covered_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor, prep_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(covered_tensor)\n",
        "\n",
        "    return hiding_output_op, reveal_output_op\n",
        "\n",
        "\n",
        "\n",
        "# Assuming other functions (get_img_batch, get_prep_network_op, get_hiding_network_op, get_reveal_network_op, get_loss_op) are defined elsewhere\\\n",
        "class CustomModel(tf.keras.Model):\n",
        "    def call(self, inputs, training=False):\n",
        "        secret_tensor, cover_tensor = inputs\n",
        "        prep_output = get_prep_network_op(secret_tensor)\n",
        "        hiding_output = get_hiding_network_op(cover_tensor, prep_output)\n",
        "        reveal_output = get_reveal_network_op(hiding_output)\n",
        "        return reveal_output\n",
        "\n",
        "\n",
        "def runFullNetwork():\n",
        "    # Variables to track the last executed epoch and step\n",
        "    current_epoch = tf.Variable(0, dtype=tf.int64)\n",
        "    current_step = tf.Variable(0, dtype=tf.int64)\n",
        "\n",
        "    model = CustomModel()\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=lambda y_true, y_pred: get_loss_op(y_true, y_pred, y_true, y_pred, BETA),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Checkpointing\n",
        "    checkpoint = tf.train.Checkpoint(model=model, optimizer=model.optimizer, current_epoch=current_epoch, current_step=current_step)\n",
        "    manager = tf.train.CheckpointManager(checkpoint, CHECKPOINTS_PATH, max_to_keep=5)\n",
        "\n",
        "    # Restore the latest checkpoint\n",
        "    if manager.latest_checkpoint:\n",
        "      checkpoint.restore(manager.latest_checkpoint).expect_partial()\n",
        "      print(f\"Restored from {manager.latest_checkpoint}, epoch {current_epoch.numpy()}, step {current_step.numpy()}\")\n",
        "    else:\n",
        "      print(\"Training from scratch\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(current_epoch.numpy(), EPOCHS):\n",
        "        for step, (secret_batch, cover_batch) in enumerate(train_dataset, start=current_step.numpy()):\n",
        "            print(\"Executing: EPOCH \" + str(epoch) + \" STEP \" + str(step) + \"\\n\")\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = model([secret_batch, cover_batch])\n",
        "                loss, _, _ = get_loss_op(secret_batch, predictions, cover_batch, predictions, BETA)\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "            current_step.assign(step)  # Update the current step\n",
        "            manager.save()\n",
        "            # Logging\n",
        "            #with summary_writer.as_default():\n",
        "                #tf.summary.scalar('loss', loss, step=epoch * (len(files_list) // BATCH_SIZE) + step)\n",
        "\n",
        "            if step % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Step {step}, Loss: {loss.numpy()}\")\n",
        "\n",
        "        current_epoch.assign(epoch + 1)  # Update the current epoch\n",
        "        current_step.assign(0)  # Reset step at the start of each new epoch\n",
        "\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12EqGxE0w0uS"
      },
      "source": [
        "## Network Definitions\n",
        "The three networks are identical in terms of structure.\n",
        "\n",
        "1. The Prepare network takes in the **Secret Image** and outputs a (BATCH_SIZE,INPUT_HEIGHT,INPUT_WEIGHT,150) tensor.\n",
        "\n",
        "2. The Cover network takes in the output from 1. , and a *Cover Image*. It concatenates these two tensors , giving a (BATCH_SIZE,INPUT_HEIGHT,INPUT_WEIGHT,153) tensor. Then it performs Convolutions , and outputs a (BATCH_SIZE,INPUT_HEIGHT,INPUT_WEIGHT,3) image.\n",
        "\n",
        "3. The Reveal Network Takes in the output image from Cover Network , and outputs the Revealed Image (which is supposed to look like the **Secret Image**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoTr1rHaKMZn"
      },
      "outputs": [],
      "source": [
        " # Data loading\n",
        "imgNett_files_list = glob.glob(join(TRAIN_PATH + \"imagenette/\", \"*\"))\n",
        "Linn_files_list = glob.glob(join(TRAIN_PATH + \"Linnaeus/**/*\", \"*.jpg\"), recursive=True)\n",
        "files_list = imgNett_files_list + Linn_files_list\n",
        "\n",
        "\n",
        "def data_generator():\n",
        "    while True:\n",
        "        yield get_img_batch(files_list, BATCH_SIZE)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    data_generator,\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=([None, 224, 224, 3], [None, 224, 224, 3]))\n",
        "train_dataset = train_dataset.take(len(files_list) // BATCH_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "higBYtzUxaJb"
      },
      "source": [
        "# Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQpzHM0VKczB",
        "outputId": "286edcb2-b292-4372-e6b1-4cde911c9273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored from /content/drive/MyDrive/Yashi/Saved-Stego-Models/checkpoints_NoNL/ckpt-118, epoch 0, step 117\n",
            "Executing: EPOCH 0 STEP 117\n",
            "\n",
            "Executing: EPOCH 0 STEP 118\n",
            "\n",
            "Executing: EPOCH 0 STEP 119\n",
            "\n",
            "Executing: EPOCH 0 STEP 120\n",
            "\n",
            "Executing: EPOCH 0 STEP 121\n",
            "\n",
            "Executing: EPOCH 0 STEP 122\n",
            "\n",
            "Executing: EPOCH 0 STEP 123\n",
            "\n",
            "Executing: EPOCH 0 STEP 124\n",
            "\n",
            "Executing: EPOCH 0 STEP 125\n",
            "\n",
            "Executing: EPOCH 0 STEP 126\n",
            "\n",
            "Executing: EPOCH 0 STEP 127\n",
            "\n",
            "Executing: EPOCH 0 STEP 128\n",
            "\n",
            "Executing: EPOCH 0 STEP 129\n",
            "\n",
            "Executing: EPOCH 0 STEP 130\n",
            "\n",
            "Executing: EPOCH 0 STEP 131\n",
            "\n",
            "Executing: EPOCH 0 STEP 132\n",
            "\n",
            "Executing: EPOCH 0 STEP 133\n",
            "\n",
            "Executing: EPOCH 0 STEP 134\n",
            "\n",
            "Executing: EPOCH 0 STEP 135\n",
            "\n",
            "Executing: EPOCH 0 STEP 136\n",
            "\n",
            "Executing: EPOCH 0 STEP 137\n",
            "\n",
            "Executing: EPOCH 0 STEP 138\n",
            "\n",
            "Executing: EPOCH 0 STEP 139\n",
            "\n",
            "Executing: EPOCH 0 STEP 140\n",
            "\n",
            "Executing: EPOCH 0 STEP 141\n",
            "\n",
            "Executing: EPOCH 0 STEP 142\n",
            "\n",
            "Executing: EPOCH 0 STEP 143\n",
            "\n",
            "Executing: EPOCH 0 STEP 144\n",
            "\n",
            "Executing: EPOCH 0 STEP 145\n",
            "\n",
            "Executing: EPOCH 0 STEP 146\n",
            "\n",
            "Executing: EPOCH 0 STEP 147\n",
            "\n",
            "Executing: EPOCH 0 STEP 148\n",
            "\n",
            "Executing: EPOCH 0 STEP 149\n",
            "\n",
            "Executing: EPOCH 0 STEP 150\n",
            "\n",
            "Executing: EPOCH 0 STEP 151\n",
            "\n",
            "Executing: EPOCH 0 STEP 152\n",
            "\n",
            "Executing: EPOCH 0 STEP 153\n",
            "\n",
            "Executing: EPOCH 0 STEP 154\n",
            "\n",
            "Executing: EPOCH 0 STEP 155\n",
            "\n",
            "Executing: EPOCH 0 STEP 156\n",
            "\n",
            "Executing: EPOCH 0 STEP 157\n",
            "\n",
            "Executing: EPOCH 0 STEP 158\n",
            "\n",
            "Executing: EPOCH 0 STEP 159\n",
            "\n",
            "Executing: EPOCH 0 STEP 160\n",
            "\n",
            "Executing: EPOCH 0 STEP 161\n",
            "\n",
            "Executing: EPOCH 0 STEP 162\n",
            "\n",
            "Executing: EPOCH 0 STEP 163\n",
            "\n",
            "Executing: EPOCH 0 STEP 164\n",
            "\n",
            "Executing: EPOCH 0 STEP 165\n",
            "\n",
            "Executing: EPOCH 0 STEP 166\n",
            "\n",
            "Executing: EPOCH 0 STEP 167\n",
            "\n",
            "Executing: EPOCH 0 STEP 168\n",
            "\n",
            "Executing: EPOCH 0 STEP 169\n",
            "\n",
            "Executing: EPOCH 0 STEP 170\n",
            "\n",
            "Executing: EPOCH 0 STEP 171\n",
            "\n",
            "Executing: EPOCH 0 STEP 172\n",
            "\n",
            "Executing: EPOCH 0 STEP 173\n",
            "\n",
            "Executing: EPOCH 0 STEP 174\n",
            "\n",
            "Executing: EPOCH 0 STEP 175\n",
            "\n",
            "Executing: EPOCH 0 STEP 176\n",
            "\n",
            "Executing: EPOCH 0 STEP 177\n",
            "\n",
            "Executing: EPOCH 0 STEP 178\n",
            "\n",
            "Executing: EPOCH 0 STEP 179\n",
            "\n",
            "Executing: EPOCH 0 STEP 180\n",
            "\n",
            "Executing: EPOCH 0 STEP 181\n",
            "\n",
            "Executing: EPOCH 0 STEP 182\n",
            "\n",
            "Executing: EPOCH 0 STEP 183\n",
            "\n",
            "Executing: EPOCH 0 STEP 184\n",
            "\n",
            "Executing: EPOCH 0 STEP 185\n",
            "\n",
            "Executing: EPOCH 0 STEP 186\n",
            "\n",
            "Executing: EPOCH 0 STEP 187\n",
            "\n",
            "Executing: EPOCH 0 STEP 188\n",
            "\n",
            "Executing: EPOCH 0 STEP 189\n",
            "\n",
            "Executing: EPOCH 0 STEP 190\n",
            "\n",
            "Executing: EPOCH 0 STEP 191\n",
            "\n",
            "Executing: EPOCH 0 STEP 192\n",
            "\n",
            "Executing: EPOCH 0 STEP 193\n",
            "\n",
            "Executing: EPOCH 0 STEP 194\n",
            "\n",
            "Executing: EPOCH 0 STEP 195\n",
            "\n",
            "Executing: EPOCH 0 STEP 196\n",
            "\n",
            "Executing: EPOCH 0 STEP 197\n",
            "\n",
            "Executing: EPOCH 0 STEP 198\n",
            "\n",
            "Executing: EPOCH 0 STEP 199\n",
            "\n",
            "Executing: EPOCH 0 STEP 200\n",
            "\n",
            "Epoch 0, Step 200, Loss: -3.6183199882507324\n",
            "Executing: EPOCH 0 STEP 201\n",
            "\n",
            "Executing: EPOCH 0 STEP 202\n",
            "\n",
            "Executing: EPOCH 0 STEP 203\n",
            "\n",
            "Executing: EPOCH 0 STEP 204\n",
            "\n",
            "Executing: EPOCH 0 STEP 205\n",
            "\n",
            "Executing: EPOCH 0 STEP 206\n",
            "\n",
            "Executing: EPOCH 0 STEP 207\n",
            "\n",
            "Executing: EPOCH 0 STEP 208\n",
            "\n",
            "Executing: EPOCH 0 STEP 209\n",
            "\n",
            "Executing: EPOCH 0 STEP 210\n",
            "\n",
            "Executing: EPOCH 0 STEP 211\n",
            "\n",
            "Executing: EPOCH 0 STEP 212\n",
            "\n",
            "Executing: EPOCH 0 STEP 213\n",
            "\n",
            "Executing: EPOCH 0 STEP 214\n",
            "\n",
            "Executing: EPOCH 0 STEP 215\n",
            "\n",
            "Executing: EPOCH 0 STEP 216\n",
            "\n",
            "Executing: EPOCH 0 STEP 217\n",
            "\n",
            "Executing: EPOCH 0 STEP 218\n",
            "\n",
            "Executing: EPOCH 0 STEP 219\n",
            "\n",
            "Executing: EPOCH 0 STEP 220\n",
            "\n",
            "Executing: EPOCH 0 STEP 221\n",
            "\n",
            "Executing: EPOCH 0 STEP 222\n",
            "\n",
            "Executing: EPOCH 0 STEP 223\n",
            "\n",
            "Executing: EPOCH 0 STEP 224\n",
            "\n",
            "Executing: EPOCH 0 STEP 225\n",
            "\n",
            "Executing: EPOCH 0 STEP 226\n",
            "\n",
            "Executing: EPOCH 0 STEP 227\n",
            "\n",
            "Executing: EPOCH 0 STEP 228\n",
            "\n",
            "Executing: EPOCH 0 STEP 229\n",
            "\n",
            "Executing: EPOCH 0 STEP 230\n",
            "\n",
            "Executing: EPOCH 0 STEP 231\n",
            "\n",
            "Executing: EPOCH 0 STEP 232\n",
            "\n",
            "Executing: EPOCH 0 STEP 233\n",
            "\n",
            "Executing: EPOCH 0 STEP 234\n",
            "\n",
            "Executing: EPOCH 0 STEP 235\n",
            "\n",
            "Executing: EPOCH 0 STEP 236\n",
            "\n",
            "Executing: EPOCH 0 STEP 237\n",
            "\n",
            "Executing: EPOCH 0 STEP 238\n",
            "\n",
            "Executing: EPOCH 0 STEP 239\n",
            "\n",
            "Executing: EPOCH 0 STEP 240\n",
            "\n",
            "Executing: EPOCH 0 STEP 241\n",
            "\n",
            "Executing: EPOCH 0 STEP 242\n",
            "\n",
            "Executing: EPOCH 0 STEP 243\n",
            "\n",
            "Executing: EPOCH 0 STEP 244\n",
            "\n",
            "Executing: EPOCH 0 STEP 245\n",
            "\n",
            "Executing: EPOCH 0 STEP 246\n",
            "\n",
            "Executing: EPOCH 0 STEP 247\n",
            "\n",
            "Executing: EPOCH 0 STEP 248\n",
            "\n",
            "Executing: EPOCH 0 STEP 249\n",
            "\n",
            "Executing: EPOCH 0 STEP 250\n",
            "\n",
            "Executing: EPOCH 0 STEP 251\n",
            "\n",
            "Executing: EPOCH 0 STEP 252\n",
            "\n",
            "Executing: EPOCH 0 STEP 253\n",
            "\n",
            "Executing: EPOCH 0 STEP 254\n",
            "\n",
            "Executing: EPOCH 0 STEP 255\n",
            "\n",
            "Executing: EPOCH 0 STEP 256\n",
            "\n",
            "Executing: EPOCH 0 STEP 257\n",
            "\n",
            "Executing: EPOCH 0 STEP 258\n",
            "\n",
            "Executing: EPOCH 0 STEP 259\n",
            "\n",
            "Executing: EPOCH 0 STEP 260\n",
            "\n",
            "Executing: EPOCH 0 STEP 261\n",
            "\n",
            "Executing: EPOCH 0 STEP 262\n",
            "\n",
            "Executing: EPOCH 0 STEP 263\n",
            "\n",
            "Executing: EPOCH 0 STEP 264\n",
            "\n",
            "Executing: EPOCH 0 STEP 265\n",
            "\n",
            "Executing: EPOCH 0 STEP 266\n",
            "\n",
            "Executing: EPOCH 0 STEP 267\n",
            "\n",
            "Executing: EPOCH 0 STEP 268\n",
            "\n",
            "Executing: EPOCH 0 STEP 269\n",
            "\n",
            "Executing: EPOCH 0 STEP 270\n",
            "\n",
            "Executing: EPOCH 0 STEP 271\n",
            "\n",
            "Executing: EPOCH 0 STEP 272\n",
            "\n",
            "Executing: EPOCH 0 STEP 273\n",
            "\n",
            "Executing: EPOCH 0 STEP 274\n",
            "\n",
            "Executing: EPOCH 0 STEP 275\n",
            "\n",
            "Executing: EPOCH 0 STEP 276\n",
            "\n",
            "Executing: EPOCH 0 STEP 277\n",
            "\n",
            "Executing: EPOCH 0 STEP 278\n",
            "\n",
            "Executing: EPOCH 0 STEP 279\n",
            "\n",
            "Executing: EPOCH 0 STEP 280\n",
            "\n",
            "Executing: EPOCH 0 STEP 281\n",
            "\n",
            "Executing: EPOCH 0 STEP 282\n",
            "\n",
            "Executing: EPOCH 0 STEP 283\n",
            "\n",
            "Executing: EPOCH 0 STEP 284\n",
            "\n",
            "Executing: EPOCH 0 STEP 285\n",
            "\n",
            "Executing: EPOCH 0 STEP 286\n",
            "\n",
            "Executing: EPOCH 0 STEP 287\n",
            "\n",
            "Executing: EPOCH 0 STEP 288\n",
            "\n",
            "Executing: EPOCH 0 STEP 289\n",
            "\n",
            "Executing: EPOCH 0 STEP 290\n",
            "\n",
            "Executing: EPOCH 0 STEP 291\n",
            "\n",
            "Executing: EPOCH 0 STEP 292\n",
            "\n",
            "Executing: EPOCH 0 STEP 293\n",
            "\n",
            "Executing: EPOCH 0 STEP 294\n",
            "\n",
            "Executing: EPOCH 0 STEP 295\n",
            "\n",
            "Executing: EPOCH 0 STEP 296\n",
            "\n",
            "Executing: EPOCH 0 STEP 297\n",
            "\n",
            "Executing: EPOCH 0 STEP 298\n",
            "\n",
            "Executing: EPOCH 0 STEP 299\n",
            "\n",
            "Executing: EPOCH 0 STEP 300\n",
            "\n",
            "Epoch 0, Step 300, Loss: -3.627749443054199\n",
            "Executing: EPOCH 0 STEP 301\n",
            "\n",
            "Executing: EPOCH 0 STEP 302\n",
            "\n",
            "Executing: EPOCH 0 STEP 303\n",
            "\n",
            "Executing: EPOCH 0 STEP 304\n",
            "\n",
            "Executing: EPOCH 0 STEP 305\n",
            "\n",
            "Executing: EPOCH 0 STEP 306\n",
            "\n",
            "Executing: EPOCH 0 STEP 307\n",
            "\n",
            "Executing: EPOCH 0 STEP 308\n",
            "\n",
            "Executing: EPOCH 0 STEP 309\n",
            "\n",
            "Executing: EPOCH 0 STEP 310\n",
            "\n",
            "Executing: EPOCH 0 STEP 311\n",
            "\n",
            "Executing: EPOCH 0 STEP 312\n",
            "\n",
            "Executing: EPOCH 0 STEP 313\n",
            "\n",
            "Executing: EPOCH 0 STEP 314\n",
            "\n",
            "Executing: EPOCH 0 STEP 315\n",
            "\n",
            "Executing: EPOCH 0 STEP 316\n",
            "\n",
            "Executing: EPOCH 0 STEP 317\n",
            "\n",
            "Executing: EPOCH 0 STEP 318\n",
            "\n",
            "Executing: EPOCH 0 STEP 319\n",
            "\n",
            "Executing: EPOCH 0 STEP 320\n",
            "\n",
            "Executing: EPOCH 0 STEP 321\n",
            "\n",
            "Executing: EPOCH 0 STEP 322\n",
            "\n",
            "Executing: EPOCH 0 STEP 323\n",
            "\n",
            "Executing: EPOCH 0 STEP 324\n",
            "\n",
            "Executing: EPOCH 0 STEP 325\n",
            "\n",
            "Executing: EPOCH 0 STEP 326\n",
            "\n",
            "Executing: EPOCH 0 STEP 327\n",
            "\n",
            "Executing: EPOCH 0 STEP 328\n",
            "\n",
            "Executing: EPOCH 0 STEP 329\n",
            "\n",
            "Executing: EPOCH 0 STEP 330\n",
            "\n",
            "Executing: EPOCH 0 STEP 331\n",
            "\n",
            "Executing: EPOCH 0 STEP 332\n",
            "\n",
            "Executing: EPOCH 0 STEP 333\n",
            "\n",
            "Executing: EPOCH 0 STEP 334\n",
            "\n"
          ]
        }
      ],
      "source": [
        "runFullNetwork()\n",
        "#runAbbreviatedNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfF2iM7ngP1-"
      },
      "source": [
        "# Loading \"a\" Fully-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OFYO8ZyV1xt",
        "outputId": "1c6c44a4-c32b-465f-8d58-69c141da3ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the model path to load: \n",
            "Model /content/drive/MyDrive/Yashi/Saved-Stego-Models/Final_Trained_Model_P75_11-01-2023-481 successfully restored.\n"
          ]
        }
      ],
      "source": [
        "#loading a fully trained model to use for Experiements\n",
        "inputModelPath = input(\"Enter the model path to load: \")\n",
        "if (inputModelPath == \"\"):\n",
        "  #inputModelPath = \"TrainedModel-10-02-2022_01_37_02-4455-11881\"\n",
        "  #AK : CHANGED to most recent!\n",
        "  inputModelPath = \"Final_Trained_Model_P75_11-01-2023-481\"\n",
        "  #inputModelPath = \"AK_Trained_Model_01-14-2023-9655\"\n",
        "\n",
        "MODEL_PATH = SAVED_STEGO_MODEL_DIRECTORY_PATH + inputModelPath\n",
        "\n",
        "try:\n",
        "  saver.restore(sess, MODEL_PATH)\n",
        "  tf.train.load_checkpoint(MODEL_PATH)\n",
        "  print(\"Model \" + MODEL_PATH + \" successfully restored.\")\n",
        "except:\n",
        "  now = datetime.now()\n",
        "  dt_string = now.strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
        "  inputModelPath = \"TrainedModel-\" + dt_string\n",
        "  MODEL_PATH = SAVED_STEGO_MODEL_DIRECTORY_PATH + inputModelPath\n",
        "  print(\"This model cannot be restored or does not exist. Defaulting to \" + MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWt1jrQmgqM_"
      },
      "source": [
        "# Experimental Results\n",
        "### Calculate Performance metrics on sample (Cover/Secret) image pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vjwg0DDcclq"
      },
      "outputs": [],
      "source": [
        "#Author : Amal Khalifa\n",
        "#Created Dec. 2022\n",
        "\n",
        "#Experimental Results\n",
        "#Calculate Performance metrics, such as PSNR, SSIM, MSE, etc.\n",
        "#10 pairs of (cover, secret) --> 10 pairs of (hidden, revealed)\n",
        "#The (hidden, revealed) images will be created and saved in RES_IMG_PATH\n",
        "\n",
        "from skimage.metrics.simple_metrics import peak_signal_noise_ratio\n",
        "\n",
        "TEST_IMG_PATH = '/content/drive/MyDrive/Yashi/Test Images/'\n",
        "RES_IMG_PATH = '/content/drive/MyDrive/Yashi/Results/'\n",
        "\n",
        "coverImgList = [\"Baboon\", \"Berries\", \"Chainsaws\", \"Church\", \"Dog\", \"Fish\", \"French Horn\", \"Garbage Truck\", \"Gas Pump\", \"Golf Balls\"]\n",
        "secretImgList = [\"Graffiti\", \"Karaoke\", \"Lena\", \"Lotus\", \"Parachute\", \"Parrot\", \"Pens\", \"Peppers\", \"Stained Glass\", \"Thistle\"]\n",
        "\n",
        "for i in  range(len(coverImgList)):\n",
        "  #load images\n",
        "  cover = Image.open(TEST_IMG_PATH + coverImgList[i] +\".png\").convert(\"RGB\")\n",
        "  secret = Image.open(TEST_IMG_PATH + secretImgList[i] + \".png\").convert(\"RGB\")\n",
        "\n",
        "  #convert into float\n",
        "  cover = np.array(ImageOps.fit(cover, (224, 224)), dtype=np.float32)\n",
        "  cover /= 255.\n",
        "  secret = np.array(ImageOps.fit(secret, (224, 224)), dtype=np.float32)\n",
        "  secret /= 255.\n",
        "\n",
        "  secrets = [secret]\n",
        "  covers = [cover]\n",
        "\n",
        "  #Use the model to hide..\n",
        "  hidden = sess.run(deploy_hide_image_op, feed_dict = {'input_prep:0': secrets,'input_hide:0': covers})\n",
        "  #hidden = np.clip(hidden, 0, 1)\n",
        "  #plt.imsave(RES_IMG_PATH + \"Stego_\"+str(i)+\".png\", np.reshape(hidden.squeeze(),(0.8784, 0.8784, 0.0118)))\n",
        "\n",
        "  #Use the model to extract..\n",
        "  revealed = sess.run(deploy_reveal_image_op,feed_dict={'deploy_covered:0':hidden})\n",
        "  #revealed = np.clip(revealed, 0, 1)\n",
        "  #plt.imsave(RES_IMG_PATH + \"retrieved_\"+str(i)+\".png\", np.reshape(revealed.squeeze(),(0.8784, 0.8784, 0.0118)))\n",
        "\n",
        "\n",
        "  #show images\n",
        "  #Cover...\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout(pad = 0)\n",
        "  plt.imshow(cover)\n",
        "  plt.show()\n",
        "  #Secret...\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout(pad = 0)\n",
        "  plt.imshow(secret)\n",
        "  plt.show()\n",
        "  #stego...\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout(pad = 0)\n",
        "  plt.imshow(hidden.squeeze())\n",
        "  plt.show()\n",
        "  #revealed...\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout(pad = 0)\n",
        "  plt.imshow(revealed.squeeze())\n",
        "  plt.show()\n",
        "\n",
        "  #Computing Performance Metrics\n",
        "  #PSNR\n",
        "  coverAndHiddenPSNR = peak_signal_noise_ratio(cover, hidden.squeeze())\n",
        "  print(\"PSNR between cover and hidden image (imperceptibility): \" + str(coverAndHiddenPSNR))\n",
        "\n",
        "  #SSIM\n",
        "  secretAndExtractedSSIM = ssim(secret, revealed.squeeze(), multichannel=True)\n",
        "  print(\"SSIM between secret and extracted image (recoverability): \" + str(secretAndExtractedSSIM))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xlqtGuqw0ui"
      },
      "outputs": [],
      "source": [
        "#Author : Guzman\n",
        "#Last Updated: April 2022\n",
        "\n",
        "#Testing the trained model on ONE image\n",
        "covers, secrets = get_img_batch(files_list=files_list,batch_size=1)\n",
        "ROOT_PATH = '/content/drive/MyDrive/Yashi/'\n",
        "\n",
        "#sample images\n",
        "coverimgName = \"Golf Balls\"\n",
        "hiddenimgName = \"Thistle\"\n",
        "\n",
        "#start debug\n",
        "if (True):\n",
        "  covers = Image.open(ROOT_PATH + \"testing_images/\" + \"riginal Cover.png\").convert(\"RGB\")\n",
        "  secrets = Image.open(ROOT_PATH + \"testing_images/\" + \"Original Hidden.png\").convert(\"RGB\")\n",
        "\n",
        "  secrets = np.array(ImageOps.fit(secrets, (224, 224)), dtype=np.float32)\n",
        "  covers = np.array(ImageOps.fit(covers, (224, 224)), dtype=np.float32)\n",
        "\n",
        "  secrets /= 255.\n",
        "  covers /= 255.\n",
        "\n",
        "  secrets = [secrets]\n",
        "  covers = [covers]\n",
        "\n",
        "  covers, secrets = np.array(covers), np.array(secrets)\n",
        "#end debug\n",
        "\n",
        "cover = covers.squeeze()\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.imshow(cover)\n",
        "0\n",
        "plt.show()\n",
        "\n",
        "secret = secrets.squeeze()\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.imshow(secret)\n",
        "plt.show()\n",
        "\n",
        "hidden = sess.run(deploy_hide_image_op, feed_dict = {'input_prep:0': secrets,'input_hide:0': covers})\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.imshow(hidden.squeeze())\n",
        "plt.show()\n",
        "#plt.imsave(\"/content/drive/MyDrive/Colab Notebooks/testing_images/Control Images/Results/\" + coverimgName + \".jpg\", np.reshape(hidden.squeeze(), (224, 224, 3)))\n",
        "\n",
        "revealed = sess.run(deploy_reveal_image_op,feed_dict={'deploy_covered:0':hidden})\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.imshow(revealed.squeeze())\n",
        "#plt.imsave(\"/content/drive/MyDrive/Colab Notebooks/testing_images/Control Images/Results/\" + hiddenimgName + \".jpg\", revealed.squeeze())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFlYo55tjeAM"
      },
      "outputs": [],
      "source": [
        "#Author : Guzman\n",
        "#Last Updated: April 2022\n",
        "\n",
        "#Calculate the STego performance metrics, such as PSNR, SSIM, MSE, etc.\n",
        "#10 pairs of cover secret --> 10 oairs of hidden revealed\n",
        "#The images has been created already and saved in METRIC_TESTING_IMAGES_PATH\n",
        "\n",
        "from skimage.metrics.simple_metrics import peak_signal_noise_ratio\n",
        "\n",
        "avgCoverAndHiddenSSIM = 0\n",
        "avgSecretAndExtractedSSIM = 0\n",
        "avgCoverAndHiddenMSE = 0\n",
        "avgSecretAndExtractedMSE = 0\n",
        "avgCoverAndHiddenPSNR = 0\n",
        "avgSecretAndExtractedPSNR = 0\n",
        "avgCoverAndHiddenNCC = 0\n",
        "avgSecretAndExtractedNCC = 0\n",
        "\n",
        "numberOfImages = 20\n",
        "for imageNumber in range(1, numberOfImages):\n",
        "\n",
        "  coverImg =    img_as_float(Image.open(METRIC_TESTING_IMAGES_PATH + str(imageNumber) + \"_cover.png\"))\n",
        "  hiddenImg =   img_as_float(Image.open(METRIC_TESTING_IMAGES_PATH + str(imageNumber) + \"_hidden.png\"))\n",
        "  stegoImg =   img_as_float(Image.open(METRIC_TESTING_IMAGES_PATH + str(imageNumber) + \"_stego.png\"))\n",
        "  extractedImg = img_as_float(Image.open(METRIC_TESTING_IMAGES_PATH + str(imageNumber) + \"_uncovered.png\"))\n",
        "\n",
        "  print(\"Test results #\" + imageNumber)\n",
        "\n",
        "  #SSIM\n",
        "  coverAndHiddenSSIM = ssim(coverImg, stegoImg, multichannel=True)\n",
        "  secretAndExtractedSSIM = ssim(hiddenImg, extractedImg, multichannel=True)\n",
        "  avgCoverAndHiddenSSIM = avgCoverAndHiddenSSIM + coverAndHiddenSSIM\n",
        "  avgSecretAndExtractedSSIM = avgSecretAndExtractedSSIM + secretAndExtractedSSIM\n",
        "  print(\"SSIM between cover and hidden image (imperceptibility): \" + str(coverAndHiddenSSIM))\n",
        "  print(\"SSIM between secret and extracted image (recoverability): \" + str(secretAndExtractedSSIM))\n",
        "\n",
        "  #PSNR\n",
        "  coverAndHiddenPSNR = peak_signal_noise_ratio(coverImg, stegoImg)\n",
        "  secretAndExtractedPSNR = peak_signal_noise_ratio(hiddenImg, extractedImg)\n",
        "  avgCoverAndHiddenPSNR = avgCoverAndHiddenPSNR + coverAndHiddenPSNR\n",
        "  avgSecretAndExtractedPSNR = avgSecretAndExtractedPSNR + secretAndExtractedPSNR\n",
        "  print(\"PSNR between cover and hidden image (imperceptibility): \" + str(coverAndHiddenPSNR))\n",
        "  print(\"PSNR between secret and extracted image (recoverability): \" + str(secretAndExtractedPSNR))\n",
        "\n",
        "  #MSE\n",
        "  coverAndHiddenMSE = mean_squared_error(coverImg, stegoImg)\n",
        "  secretAndExtractedMSE = mean_squared_error(hiddenImg, extractedImg)\n",
        "  avgCoverAndHiddenMSE = avgCoverAndHiddenMSE + coverAndHiddenMSE\n",
        "  avgSecretAndExtractedMSE = avgSecretAndExtractedMSE + secretAndExtractedMSE\n",
        "  print(\"MSE between cover and hidden image (imperceptibility): \" + str(coverAndHiddenMSE))\n",
        "  print(\"MSE between secret and extracted image (recoverability): \" + str(secretAndExtractedMSE))\n",
        "\n",
        "  #NCC\n",
        "  '''a = coverImg\n",
        "  b = stegoImg\n",
        "  a = (a - np.mean(a)) / (np.std(a) * len(a))\n",
        "  b = (b - np.mean(b)) / (np.std(b))\n",
        "  c = np.correlate(np.ndarray.flatten(a), np.ndarray.flatten(b), 'full')\n",
        "  coverAndHiddenNCC = c\n",
        "  a = hiddenImg\n",
        "  b = extractedImg\n",
        "  a = (a - np.mean(a)) / (np.std(a) * len(a))\n",
        "  b = (b - np.mean(b)) / (np.std(b))\n",
        "  c = np.correlate(a, b, 'full')\n",
        "  secretAndExtractedNCC = c\n",
        "  avgCoverAndHiddenNCC = avgCoverAndHiddenNCC + coverAndHiddenNCC\n",
        "  avgSecretAndExtractedNCC = avgSecretAndExtractedNCC + secretAndExtractedNCC\n",
        "  print(\"NCC between cover and hidden image (imperceptibility): \" + str(coverAndHiddenNCC))\n",
        "  print(\"NCC between secret and extracted image (recoverability): \" + str(secretAndExtractedNCC))'''\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"Average SSIM between cover and hidden images: \" + str(avgCoverAndHiddenSSIM / numberOfImages))\n",
        "print(\"Average SSIM between secret and extracted images: \" + str(avgSecretAndExtractedSSIM / numberOfImages))\n",
        "print(\"Average PSNR between cover and hidden images: \" + str(avgCoverAndHiddenPSNR / numberOfImages))\n",
        "print(\"Average PSNR between secret and extracted images: \" + str(avgSecretAndExtractedPSNR / numberOfImages))\n",
        "print(\"Average MSE between cover and hidden images: \" + str(avgCoverAndHiddenMSE / numberOfImages))\n",
        "print(\"Average MSE between secret and extracted images: \" + str(avgSecretAndExtractedMSE / numberOfImages))\n",
        "print(\"Average NCC between cover and hidden images: \" + str(avgCoverAndHiddenNCC / numberOfImages))\n",
        "print(\"Average NCC between secret and extracted images: \" + str(avgSecretAndExtractedNCC / numberOfImages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LitR0MtEseVW",
        "outputId": "3722a59e-a0fa-4717-c12e-b43f31c1c819"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-af5f5c51879a>:30: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  OriginalNetworkStegoSSIM = ssim(coverImg, stegoImg, multichannel=True)\n",
            "/usr/local/lib/python3.10/dist-packages/skimage/metrics/simple_metrics.py:163: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return 10 * np.log10((data_range ** 2) / err)\n",
            "<ipython-input-19-af5f5c51879a>:41: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  OriginalNetworkRecoveredSSIM = ssim(hiddenImg, extractedImg, multichannel=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n",
            "SSIM between cover and stego image: 1.0\n",
            "PSNR between cover and stego image: inf\n",
            "SSIM between hidden and extracted image: 1.0\n",
            "MSE between hidden and extracted image: 0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing the Model\n",
        "#Calculate the network metrics, such as PSNR, SSIM, MSE, etc.\n",
        "#Created by Anthony\n",
        "\n",
        "from skimage.metrics.simple_metrics import peak_signal_noise_ratio\n",
        "\n",
        "coverImgs = [\"Baboon\", \"Berries\", \"Chainsaws\", \"Church\", \"Dog\", \"Fish\", \"French Horn\", \"Garbage Truck\", \"Gas Pump\", \"Golf Balls\"]\n",
        "hiddenImgs = [\"Graffiti\", \"Karaoke\", \"Lena\", \"Lotus\", \"Parachute\", \"Parrot\", \"Pens\", \"Peppers\", \"Stained Glass\", \"Thistle\"]\n",
        "fileType = \".png\"\n",
        "\n",
        "for x in range(10):\n",
        "\n",
        "  coverImgFileName = \"/content/drive/MyDrive/Yashi/Test Images/\" + coverImgs[x] + fileType\n",
        "  stegoImgFileName = \"/content/drive/MyDrive/Yashi/Test Images//\" + coverImgs[x] + fileType\n",
        "  hiddenImgFileName = \"/content/drive/MyDrive/Yashi/Test Images//\" + hiddenImgs[x] + fileType\n",
        "  extractedImgFileName = \"/content/drive/MyDrive/Yashi/Test Images//\" + hiddenImgs[x] + fileType\n",
        "\n",
        "  #coverImgFileName = \"/content/drive/MyDrive/Colab Notebooks/testing_images/Original Version Output Cover\"  + fileType\n",
        "  #stegoImgFileName = \"/content/drive/MyDrive/Colab Notebooks/testing_images/Original Version Output Stego\"  + fileType\n",
        "  #hiddenImgFileName = \"/content/drive/MyDrive/Colab Notebooks/testing_images/Original Version Output Hidden\"  + fileType\n",
        "  #extractedImgFileName = \"/content/drive/MyDrive/Colab Notebooks/testing_images/Original Version Output Extracted\"  + fileType\n",
        "\n",
        "  coverImg =     img_as_float(Image.open(coverImgFileName))\n",
        "  stegoImg =     img_as_float(Image.open(stegoImgFileName))\n",
        "  hiddenImg =    img_as_float(Image.open(hiddenImgFileName))\n",
        "  extractedImg = img_as_float(Image.open(extractedImgFileName))\n",
        "\n",
        "  #print(\"Cover: \" + coverImgs[x] +  \"     Hidden: \" + hiddenImgs[x])\n",
        "\n",
        "  OriginalNetworkStegoSSIM = ssim(coverImg, stegoImg, multichannel=True)\n",
        "  print(\"SSIM between cover and stego image: \" + str(float(format(OriginalNetworkStegoSSIM, '.5f'))))\n",
        "\n",
        "  #PSNR\n",
        "  OriginalNetworkStegoPSNR = peak_signal_noise_ratio(coverImg, stegoImg)\n",
        "  #OriginalNetworkRecoveredPSNR = peak_signal_noise_ratio(hiddenImg, extractedImg)\n",
        "  print(\"PSNR between cover and stego image: \" + str(float(format(OriginalNetworkStegoPSNR, '.5f'))))\n",
        "  #print(\"PSNR between hidden and extracted image: \" + str(OriginalNetworkRecoveredPSNR))\n",
        "\n",
        "  #MSE\n",
        "  #coverAndHiddenMSE = mean_squared_error(coverImg, stegoImg)\n",
        "  OriginalNetworkRecoveredSSIM = ssim(hiddenImg, extractedImg, multichannel=True)\n",
        "  print(\"SSIM between hidden and extracted image: \" + str(float(format(OriginalNetworkRecoveredSSIM, '.5f'))))\n",
        "  secretAndExtractedMSE = mean_squared_error(hiddenImg, extractedImg)\n",
        "  #print(\"MSE between cover and stego image: \" + str(coverAndHiddenMSE))\n",
        "  print(\"MSE between hidden and extracted image: \" + str(float(format(secretAndExtractedMSE, '.5f'))))\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHvK8H4k0wSp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from skimage import img_as_float\n",
        "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio, mean_squared_error\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    if img.mode == 'RGBA':\n",
        "        img = img.convert('RGB')\n",
        "    img = img.resize((224, 224))\n",
        "    return img_as_float(img)\n",
        "\n",
        "results_list = []\n",
        "\n",
        "coverImgs = [\"Baboon\", \"Berries\", \"Chainsaws\", \"Church\", \"Dog\", \"Fish\", \"French Horn\", \"Garbage Truck\", \"Gas Pump\", \"Golf Balls\"]\n",
        "hiddenImgs = [\"Graffiti\", \"Karaoke\", \"Lena\", \"Lotus\", \"Parachute\", \"Parrot\", \"Pens\", \"Peppers\", \"Stained Glass\", \"Thistle\"]\n",
        "fileType = \".png\"\n",
        "\n",
        "for x in range(10):\n",
        "    coverImgFileName = \"/content/drive/MyDrive/Yashi/Test Images/\" + coverImgs[x] + fileType\n",
        "    hiddenImgFileName = \"/content/drive/MyDrive/Yashi/Test Images/\" + hiddenImgs[x] + fileType\n",
        "\n",
        "    coverImg = preprocess_image(coverImgFileName)\n",
        "    hiddenImg = preprocess_image(hiddenImgFileName)\n",
        "\n",
        "    # Generate stego and extracted images\n",
        "    stegoImg = sess.run(deploy_hide_image_op, feed_dict={\"input_prep:0\": [hiddenImg], \"input_hide:0\": [coverImg]})\n",
        "    extractedImg = sess.run(deploy_reveal_image_op, feed_dict={\"deploy_covered:0\": stegoImg})\n",
        "\n",
        "    # Display images\n",
        "    images = [coverImg, hiddenImg, stegoImg[0], extractedImg[0]]\n",
        "    titles = [\"Cover\", \"Secret\", \"Stego\", \"Revealed\"]\n",
        "\n",
        "    for img, title in zip(images, titles):\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout(pad=0)\n",
        "        plt.imshow(img.squeeze())\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "\n",
        "    # Compute metrics\n",
        "    coverAndStegoPSNR = peak_signal_noise_ratio(coverImg, stegoImg[0])\n",
        "    print(\"PSNR between cover and stego image (imperceptibility): \" + str(coverAndStegoPSNR))\n",
        "\n",
        "    secretAndExtractedSSIM = ssim(hiddenImg, extractedImg[0], multichannel=True)\n",
        "    print(\"SSIM between secret and extracted image (recoverability): \" + str(secretAndExtractedSSIM))\n",
        "\n",
        "    # Append results to results_list\n",
        "    results_list.append([\"SteGuz\", \"Stego\", coverImgs[x], coverAndStegoPSNR, \"N/A\", \"No\"])\n",
        "    results_list.append([\"SteGuz\", \"Extracted\", hiddenImgs[x], \"N/A\", secretAndExtractedSSIM, \"No\"])\n",
        "\n",
        "# Convert results_list to DataFrame and save to CSV\n",
        "df = pd.DataFrame(results_list, columns=['Model', 'ImageType', 'ImageName', 'PSNR', 'SSIM', 'Noise Layer'])\n",
        "df.to_csv(\"/content/drive/MyDrive/Yashi/Saved-Stego-Models/Results_P75.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}